#!/usr/bin/env python3
"""
ì™„ì „í•œ BioHama ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

ìƒˆë¡œ êµ¬í˜„ëœ SparseAttentionê³¼ TerminationModuleì´ í¬í•¨ëœ
ì™„ì „í•œ BioHama ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
from typing import Dict, Any

# BioHama ëª¨ë“ˆ import
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from biohama.biohama_system import BioHamaSystem


def test_complete_system():
    """ì™„ì „í•œ BioHama ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ§  ì™„ì „í•œ BioHama ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    # ì‹œìŠ¤í…œ ì„¤ì •
    config = {
        'device': 'cpu',
        'meta_router': {
            'input_dim': 512,
            'hidden_dim': 256,
            'num_heads': 8,
            'routing_strategy': 'attention'
        },
        'cognitive_state': {
            'memory_size': 1000,
            'attention_dim': 256,
            'emotion_dim': 64
        },
        'working_memory': {
            'capacity': 100,
            'consolidation_threshold': 0.7
        },
        'decision_engine': {
            'policy_dim': 256,
            'value_dim': 128
        },
        'attention_control': {
            'attention_dim': 256,
            'num_heads': 8
        },
        'sparse_attention': {
            'd_model': 512,
            'num_heads': 8,
            'seq_len': 128,
            'sparsity_ratio': 0.8,
            'local_window': 32,
            'pattern_dim': 64,
            'num_patterns': 8
        },
        'termination_module': {
            'input_dim': 512,
            'confidence_threshold': 0.7,
            'quality_threshold': 0.6,
            'patience': 3,
            'min_delta': 0.001,
            'max_iterations': 10
        },
        'message_passing': {
            'queue_size': 1000,
            'timeout': 5.0
        },
        'bio_agrpo': {
            'policy_dim': 256,
            'value_dim': 128,
            'learning_rate': 0.001
        }
    }
    
    # BioHama ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("ğŸ”„ BioHama ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    biohama = BioHamaSystem(config)
    print("âœ… BioHama ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ì‹œìŠ¤í…œ ì‹œì‘
    biohama.start()
    print("âœ… BioHama ì‹œìŠ¤í…œ ì‹œì‘ë¨")
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
    test_scenarios = [
        {
            'name': 'ê¸°ë³¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬',
            'inputs': {
                'text': 'ì•ˆë…•í•˜ì„¸ìš”. BioHama ì‹œìŠ¤í…œì…ë‹ˆë‹¤.',
                'task_type': 'text_processing'
            }
        },
        {
            'name': 'ë³µì¡í•œ ì¶”ë¡  ì‘ì—…',
            'inputs': {
                'question': 'ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ” ì–´ë–»ê²Œ ë ê¹Œìš”?',
                'context': 'ìµœê·¼ AI ê¸°ìˆ ì˜ ë°œì „ê³¼ ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­',
                'task_type': 'reasoning'
            }
        },
        {
            'name': 'ë‹¤ì¤‘ ëª¨ë‹¬ ì…ë ¥',
            'inputs': {
                'text': 'ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”',
                'image_features': torch.randn(1, 512),
                'task_type': 'multimodal'
            }
        },
        {
            'name': 'í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤',
            'inputs': {
                'training_data': torch.randn(10, 512),
                'labels': torch.randint(0, 5, (10,)),
                'task_type': 'learning'
            }
        }
    ]
    
    print(f"\nğŸ“‹ {len(test_scenarios)}ê°œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰")
    print("-" * 80)
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ”„ ì‹œë‚˜ë¦¬ì˜¤ {i}: {scenario['name']}")
        print(f"   ì…ë ¥: {list(scenario['inputs'].keys())}")
        
        try:
            # ì…ë ¥ ì²˜ë¦¬
            result = biohama.process_input(scenario['inputs'])
            
            print(f"   âœ… ì²˜ë¦¬ ì™„ë£Œ")
            print(f"   ì¶œë ¥ í‚¤: {list(result.keys())}")
            
            # ê²°ê³¼ ë¶„ì„
            if 'confidence' in result:
                print(f"   ì‹ ë¢°ë„: {result['confidence']:.3f}")
            if 'quality' in result:
                print(f"   í’ˆì§ˆ: {result['quality']:.3f}")
            if 'sparsity_ratio' in result:
                print(f"   í¬ì†Œì„±: {result['sparsity_ratio']:.3f}")
            if 'should_terminate' in result:
                print(f"   ì¢…ë£Œ ì—¬ë¶€: {result['should_terminate']}")
                
        except Exception as e:
            print(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    # ì‹œìŠ¤í…œ í†µê³„ í™•ì¸
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ í†µê³„")
    print("-" * 80)
    
    stats = biohama.get_system_statistics()
    
    print(f"ì‹œìŠ¤í…œ ê°€ë™ ì‹œê°„: {stats.get('uptime', 'N/A')}")
    print(f"ì²˜ë¦¬ëœ ì…ë ¥ ìˆ˜: {stats.get('processed_inputs', 0)}")
    print(f"í™œì„± ëª¨ë“ˆ ìˆ˜: {stats.get('active_modules', 0)}")
    
    # ëª¨ë“ˆë³„ í†µê³„
    if 'module_stats' in stats:
        print(f"\nëª¨ë“ˆë³„ í†µê³„:")
        for module_name, module_stat in stats['module_stats'].items():
            print(f"  {module_name}: {module_stat}")
    
    # í¬ì†Œ ì–´í…ì…˜ í†µê³„
    if hasattr(biohama, 'sparse_attention'):
        sparse_stats = biohama.sparse_attention.get_attention_stats()
        print(f"\ní¬ì†Œ ì–´í…ì…˜ í†µê³„:")
        print(f"  ê³„ì‚° ì ˆì•½: {sparse_stats['computation_savings']:.3f}")
        print(f"  ì´ í† í°: {sparse_stats['total_tokens']:,}")
        print(f"  í¬ì†Œ í† í°: {sparse_stats['sparse_tokens']:,}")
    
    # ì¢…ë£Œ ëª¨ë“ˆ í†µê³„
    if hasattr(biohama, 'termination_module'):
        termination_stats = biohama.termination_module.get_termination_stats()
        print(f"\nì¢…ë£Œ ëª¨ë“ˆ í†µê³„:")
        print(f"  ì´ ì²´í¬: {termination_stats['total_checks']}")
        print(f"  ì¡°ê¸° ì¢…ë£Œ: {termination_stats['early_terminations']}")
        print(f"  í‰ê·  ë°˜ë³µ: {termination_stats['avg_iterations']:.2f}")
    
    # ì‹œìŠ¤í…œ ì¤‘ì§€
    biohama.stop()
    print(f"\nâœ… BioHama ì‹œìŠ¤í…œ ì¤‘ì§€ë¨")
    
    return True


def test_performance_optimization():
    """ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("âš¡ ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    # ì„¤ì •
    config = {
        'device': 'cpu',
        'sparse_attention': {
            'd_model': 256,
            'num_heads': 4,
            'seq_len': 64,
            'sparsity_ratio': 0.9,  # ë†’ì€ í¬ì†Œì„±
            'local_window': 16,
            'pattern_dim': 32,
            'num_patterns': 4
        },
        'termination_module': {
            'input_dim': 256,
            'confidence_threshold': 0.5,  # ë‚®ì€ ì„ê³„ê°’
            'quality_threshold': 0.4,
            'patience': 2,
            'min_delta': 0.01,
            'max_iterations': 5
        }
    }
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    biohama = BioHamaSystem(config)
    biohama.start()
    
    print("ğŸ”„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    # ëŒ€ìš©ëŸ‰ ì…ë ¥ í…ŒìŠ¤íŠ¸
    large_input = {
        'text': 'A' * 1000,  # ê¸´ í…ìŠ¤íŠ¸
        'features': torch.randn(1, 64, 256),  # í° íŠ¹ì§• í…ì„œ
        'task_type': 'performance_test'
    }
    
    import time
    start_time = time.time()
    
    for i in range(10):
        result = biohama.process_input(large_input)
        
        if i == 0:  # ì²« ë²ˆì§¸ ê²°ê³¼ë§Œ ì¶œë ¥
            print(f"âœ… ì²« ë²ˆì§¸ ì²˜ë¦¬ ì™„ë£Œ")
            print(f"   ì²˜ë¦¬ ì‹œê°„: {time.time() - start_time:.3f}ì´ˆ")
            print(f"   í¬ì†Œì„±: {result.get('sparsity_ratio', 'N/A')}")
            print(f"   ê³„ì‚° ì ˆì•½: {result.get('computation_savings', 'N/A')}")
    
    total_time = time.time() - start_time
    avg_time = total_time / 10
    
    print(f"\nğŸ“Š ì„±ëŠ¥ ê²°ê³¼:")
    print(f"  ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.3f}ì´ˆ")
    print(f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.3f}ì´ˆ")
    print(f"  ì²˜ë¦¬ ì†ë„: {10/total_time:.1f} ìš”ì²­/ì´ˆ")
    
    biohama.stop()
    
    return True


def test_error_recovery():
    """ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("ğŸ›¡ï¸ ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    config = {
        'device': 'cpu',
        'sparse_attention': {'d_model': 128},
        'termination_module': {'input_dim': 128}
    }
    
    biohama = BioHamaSystem(config)
    biohama.start()
    
    # ë‹¤ì–‘í•œ ì—ëŸ¬ ìƒí™© í…ŒìŠ¤íŠ¸
    error_scenarios = [
        {'name': 'ë¹ˆ ì…ë ¥', 'inputs': {}},
        {'name': 'None ê°’', 'inputs': {'text': None}},
        {'name': 'ì˜ëª»ëœ íƒ€ì…', 'inputs': {'text': 123}},
        {'name': 'ë„ˆë¬´ í° í…ì„œ', 'inputs': {'features': torch.randn(1, 10000, 128)}},
    ]
    
    print("ğŸ”„ ì—ëŸ¬ ìƒí™© í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    for scenario in error_scenarios:
        print(f"  í…ŒìŠ¤íŠ¸: {scenario['name']}")
        
        try:
            result = biohama.process_input(scenario['inputs'])
            print(f"    âœ… ì •ìƒ ì²˜ë¦¬ë¨")
        except Exception as e:
            print(f"    âš ï¸ ì˜ˆìƒëœ ì—ëŸ¬: {type(e).__name__}")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    stats = biohama.get_system_statistics()
    print(f"\nâœ… ì‹œìŠ¤í…œ ìƒíƒœ: {stats.get('status', 'unknown')}")
    
    biohama.stop()
    
    return True


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ ì™„ì „í•œ BioHama ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    test_results = []
    
    try:
        # ì™„ì „í•œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        test_results.append(test_complete_system())
        
        # ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸
        test_results.append(test_performance_optimization())
        
        # ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸
        test_results.append(test_error_recovery())
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“‹ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    
    passed_tests = sum(test_results)
    total_tests = len(test_results)
    
    print(f"âœ… í†µê³¼í•œ í…ŒìŠ¤íŠ¸: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("ğŸ‰ ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        print("\nâœ¨ BioHama ì‹œìŠ¤í…œ ì™„ì„±:")
        print("   - âœ… ë©”íƒ€ ë¼ìš°í„° (ë™ì  ëª¨ë“ˆ ì„ íƒ)")
        print("   - âœ… ì¸ì§€ ìƒíƒœ ê´€ë¦¬")
        print("   - âœ… ì‘ì—… ë©”ëª¨ë¦¬")
        print("   - âœ… ì˜ì‚¬ê²°ì • ì—”ì§„")
        print("   - âœ… ì£¼ì˜ ì œì–´")
        print("   - âœ… ë™ì  í¬ì†Œ ì–´í…ì…˜ (O(nÂ²) â†’ O(n) ìµœì í™”)")
        print("   - âœ… ì—°ì‚° ì¢…ë£Œ ëª¨ë“ˆ (ì‹ ë¢°ë„ ê¸°ë°˜ ì¡°ê¸° ì¢…ë£Œ)")
        print("   - âœ… ë©”ì‹œì§€ ì „ë‹¬ ì‹œìŠ¤í…œ")
        print("   - âœ… Bio-A-GRPO í•™ìŠµ ì•Œê³ ë¦¬ì¦˜")
        print("   - âœ… ì™„ì „í•œ ì‹œìŠ¤í…œ í†µí•©")
        print("\nğŸš€ BioHama - ë‡Œê³¼í•™ì  ê¸°ë°˜ì˜ ì°¨ì„¸ëŒ€ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return True
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
