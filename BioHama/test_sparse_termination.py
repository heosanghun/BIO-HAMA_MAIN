#!/usr/bin/env python3
"""
ìƒˆë¡œ êµ¬í˜„í•œ SparseAttentionê³¼ TerminationModule í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. SparseAttentionModuleì˜ í¬ì†Œ ì–´í…ì…˜ ê¸°ëŠ¥
2. TerminationModuleì˜ ì¢…ë£Œ íŒë‹¨ ê¸°ëŠ¥
3. ë‘ ëª¨ë“ˆì˜ í†µí•© ë™ì‘
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
from typing import Dict, Any

# BioHama ëª¨ë“ˆ import
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from biohama.core.sparse_attention import SparseAttentionModule, SparseAttentionState
from biohama.core.termination_module import TerminationModule, TerminationState


def test_sparse_attention_module():
    """SparseAttentionModule í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("ğŸ§  SparseAttentionModule í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ì„¤ì •
    config = {
        'd_model': 512,
        'num_heads': 8,
        'seq_len': 128,
        'sparsity_ratio': 0.8,
        'local_window': 32,
        'pattern_dim': 64,
        'num_patterns': 8,
        'use_flash_attention': True
    }
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    config['name'] = "TestSparseAttention"
    sparse_attention = SparseAttentionModule(config)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 2
    seq_len = 64
    d_model = 512
    
    query = torch.randn(batch_size, seq_len, d_model)
    key = torch.randn(batch_size, seq_len, d_model)
    value = torch.randn(batch_size, seq_len, d_model)
    
    print(f"âœ… ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"   - ì…ë ¥ í¬ê¸°: {query.shape}")
    print(f"   - í¬ì†Œì„± ë¹„ìœ¨: {config['sparsity_ratio']}")
    
    # ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
    inputs = {
        'query': query,
        'key': key,
        'value': value,
        'seq_len': seq_len
    }
    
    outputs = sparse_attention(inputs)
    
    print(f"âœ… ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"   - ì¶œë ¥ í¬ê¸°: {outputs['attention_output'].shape}")
    print(f"   - ì‹¤ì œ í¬ì†Œì„±: {outputs['sparsity_ratio']:.3f}")
    print(f"   - ê³„ì‚° ì ˆì•½: {outputs['computation_savings']:.3f}")
    
    # ë©”íƒ€ë°ì´í„° í…ŒìŠ¤íŠ¸
    metadata = sparse_attention.get_metadata()
    complexity = sparse_attention.get_complexity()
    
    print(f"âœ… ë©”íƒ€ë°ì´í„° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"   - ëª¨ë“ˆ ì´ë¦„: {metadata['name']}")
    print(f"   - ëª¨ë“ˆ íƒ€ì…: {metadata['module_type']}")
    print(f"   - ì´ íŒŒë¼ë¯¸í„°: {complexity['total_parameters']:,}")
    print(f"   - í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {complexity['trainable_parameters']:,}")
    
    # í†µê³„ í…ŒìŠ¤íŠ¸
    stats = sparse_attention.get_attention_stats()
    print(f"âœ… í†µê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"   - ì´ í† í°: {stats['total_tokens']:,}")
    print(f"   - í¬ì†Œ í† í°: {stats['sparse_tokens']:,}")
    print(f"   - íŒ¨í„´ ë§¤ì¹­: {stats['pattern_matches']:.2f}")
    
    # í¬ì†Œì„± ì¡°ì • í…ŒìŠ¤íŠ¸
    sparse_attention.set_sparsity_ratio(0.9)
    outputs2 = sparse_attention(inputs)
    print(f"âœ… í¬ì†Œì„± ì¡°ì • í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"   - ì¡°ì •ëœ í¬ì†Œì„±: {outputs2['sparsity_ratio']:.3f}")
    
    print("âœ… SparseAttentionModule ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    return True


def test_termination_module():
    """TerminationModule í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ›‘ TerminationModule í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ì„¤ì •
    config = {
        'input_dim': 512,
        'confidence_threshold': 0.7,
        'quality_threshold': 0.6,
        'patience': 3,
        'min_delta': 0.001,
        'max_iterations': 10
    }
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    config['name'] = "TestTermination"
    termination = TerminationModule(config)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 2
    seq_len = 32
    input_dim = 512
    
    features = torch.randn(batch_size, seq_len, input_dim)
    
    print(f"âœ… ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"   - ì…ë ¥ í¬ê¸°: {features.shape}")
    print(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {config['confidence_threshold']}")
    print(f"   - í’ˆì§ˆ ì„ê³„ê°’: {config['quality_threshold']}")
    
    # ë°˜ë³µ í…ŒìŠ¤íŠ¸
    for iteration in range(5):
        inputs = {
            'features': features,
            'iteration': iteration,
            'force_continue': False
        }
        
        outputs = termination(inputs)
        
        print(f"âœ… ë°˜ë³µ {iteration + 1} í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print(f"   - ì‹ ë¢°ë„: {outputs['confidence'].mean().item():.3f}")
        print(f"   - í’ˆì§ˆ: {outputs['quality'].mean().item():.3f}")
        print(f"   - ì¢…ë£Œ ì—¬ë¶€: {outputs['should_terminate']}")
        print(f"   - ì¢…ë£Œ ì´ìœ : {outputs['stop_reasons']}")
        
        if outputs['should_terminate']:
            print(f"   - ì¡°ê¸° ì¢…ë£Œë¨!")
            break
    
    # ë©”íƒ€ë°ì´í„° í…ŒìŠ¤íŠ¸
    metadata = termination.get_metadata()
    complexity = termination.get_complexity()
    
    print(f"âœ… ë©”íƒ€ë°ì´í„° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"   - ëª¨ë“ˆ ì´ë¦„: {metadata['name']}")
    print(f"   - ëª¨ë“ˆ íƒ€ì…: {metadata['module_type']}")
    print(f"   - ì´ íŒŒë¼ë¯¸í„°: {complexity['total_parameters']:,}")
    print(f"   - í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {complexity['trainable_parameters']:,}")
    
    # í†µê³„ í…ŒìŠ¤íŠ¸
    stats = termination.get_termination_stats()
    print(f"âœ… í†µê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"   - ì´ ì²´í¬: {stats['total_checks']}")
    print(f"   - ì¡°ê¸° ì¢…ë£Œ: {stats['early_terminations']}")
    print(f"   - í‰ê·  ë°˜ë³µ: {stats['avg_iterations']:.2f}")
    print(f"   - í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.3f}")
    print(f"   - í‰ê·  í’ˆì§ˆ: {stats['avg_quality']:.3f}")
    
    # ì„ê³„ê°’ ì¡°ì • í…ŒìŠ¤íŠ¸
    termination.set_thresholds(confidence_threshold=0.5, quality_threshold=0.4)
    print(f"âœ… ì„ê³„ê°’ ì¡°ì • í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    # ìƒíƒœ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    termination.reset_early_stopping()
    print(f"âœ… ìƒíƒœ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    print("âœ… TerminationModule ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    return True


def test_integration():
    """ë‘ ëª¨ë“ˆì˜ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ”— ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ì„¤ì •
    sparse_config = {
        'd_model': 256,
        'num_heads': 4,
        'seq_len': 64,
        'sparsity_ratio': 0.7,
        'local_window': 16,
        'pattern_dim': 32,
        'num_patterns': 4
    }
    
    termination_config = {
        'input_dim': 256,
        'confidence_threshold': 0.6,
        'quality_threshold': 0.5,
        'patience': 2,
        'min_delta': 0.01,
        'max_iterations': 5
    }
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    sparse_config['name'] = "IntegrationSparse"
    termination_config['name'] = "IntegrationTermination"
    sparse_attention = SparseAttentionModule(sparse_config)
    termination = TerminationModule(termination_config)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    batch_size = 1
    seq_len = 32
    d_model = 256
    
    query = torch.randn(batch_size, seq_len, d_model)
    features = torch.randn(batch_size, seq_len, d_model)
    
    print(f"âœ… ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"   - í¬ì†Œ ì–´í…ì…˜: {sparse_attention.name}")
    print(f"   - ì¢…ë£Œ ëª¨ë“ˆ: {termination.name}")
    
    # í†µí•© ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    for iteration in range(3):
        print(f"\nğŸ”„ ë°˜ë³µ {iteration + 1} ì²˜ë¦¬:")
        
        # 1. í¬ì†Œ ì–´í…ì…˜ ì²˜ë¦¬
        sparse_inputs = {
            'query': query,
            'seq_len': seq_len
        }
        sparse_outputs = sparse_attention(sparse_inputs)
        
        print(f"   - í¬ì†Œ ì–´í…ì…˜ ì™„ë£Œ (í¬ì†Œì„±: {sparse_outputs['sparsity_ratio']:.3f})")
        
        # 2. ì¢…ë£Œ íŒë‹¨
        termination_inputs = {
            'features': features,
            'iteration': iteration,
            'force_continue': False
        }
        termination_outputs = termination(termination_inputs)
        
        print(f"   - ì¢…ë£Œ íŒë‹¨ ì™„ë£Œ (ì‹ ë¢°ë„: {termination_outputs['confidence'].mean().item():.3f})")
        print(f"   - ì¢…ë£Œ ì—¬ë¶€: {termination_outputs['should_terminate']}")
        
        if termination_outputs['should_terminate']:
            print(f"   - ğŸ”´ ì¡°ê¸° ì¢…ë£Œë¨!")
            break
        else:
            print(f"   - ğŸŸ¢ ê³„ì† ì§„í–‰")
    
    # í†µí•© í†µê³„
    sparse_stats = sparse_attention.get_attention_stats()
    termination_stats = termination.get_termination_stats()
    
    print(f"\nğŸ“Š í†µí•© í†µê³„:")
    print(f"   - í¬ì†Œ ì–´í…ì…˜ ê³„ì‚° ì ˆì•½: {sparse_stats['computation_savings']:.3f}")
    print(f"   - ì¢…ë£Œ ëª¨ë“ˆ ì¡°ê¸° ì¢…ë£Œìœ¨: {termination_stats['early_terminations']}/{termination_stats['total_checks']}")
    
    print("âœ… ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return True


def test_error_handling():
    """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("âš ï¸ ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ì˜ëª»ëœ ì…ë ¥ í…ŒìŠ¤íŠ¸
    sparse_attention = SparseAttentionModule({'name': "ErrorTestSparse"})
    termination = TerminationModule({'name': "ErrorTestTermination"})
    
    # None ì…ë ¥ í…ŒìŠ¤íŠ¸
    try:
        result = sparse_attention({'query': None})
        if result == {'query': None}:  # ì…ë ¥ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜ë¨
            print("âœ… None ì…ë ¥ ì²˜ë¦¬ ì„±ê³µ: ì…ë ¥ ê·¸ëŒ€ë¡œ ë°˜í™˜")
        else:
            print("âŒ None ì…ë ¥ ì²˜ë¦¬ ì‹¤íŒ¨")
            return False
    except Exception as e:
        print(f"âœ… None ì…ë ¥ ì²˜ë¦¬ ì„±ê³µ: {type(e).__name__}")
    
    try:
        result = termination({'features': None})
        if result == {'features': None}:  # ì…ë ¥ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜ë¨
            print("âœ… None ì…ë ¥ ì²˜ë¦¬ ì„±ê³µ: ì…ë ¥ ê·¸ëŒ€ë¡œ ë°˜í™˜")
        else:
            print("âŒ None ì…ë ¥ ì²˜ë¦¬ ì‹¤íŒ¨")
            return False
    except Exception as e:
        print(f"âœ… None ì…ë ¥ ì²˜ë¦¬ ì„±ê³µ: {type(e).__name__}")
    
    # ì˜ëª»ëœ í¬ê¸° í…ŒìŠ¤íŠ¸
    try:
        sparse_attention({'query': torch.randn(1, 10, 100)})  # ì˜ëª»ëœ í¬ê¸°
        print("âŒ ì˜ëª»ëœ í¬ê¸° ì²˜ë¦¬ ì‹¤íŒ¨")
        return False
    except Exception as e:
        print(f"âœ… ì˜ëª»ëœ í¬ê¸° ì²˜ë¦¬ ì„±ê³µ: {type(e).__name__}")
    
    print("âœ… ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return True


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ BioHama ê³ ê¸‰ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    test_results = []
    
    try:
        # ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
        test_results.append(test_sparse_attention_module())
        test_results.append(test_termination_module())
        
        # í†µí•© í…ŒìŠ¤íŠ¸
        test_results.append(test_integration())
        
        # ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        test_results.append(test_error_handling())
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    
    passed_tests = sum(test_results)
    total_tests = len(test_results)
    
    print(f"âœ… í†µê³¼í•œ í…ŒìŠ¤íŠ¸: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        print("\nâœ¨ êµ¬í˜„ëœ ê¸°ëŠ¥:")
        print("   - ë™ì  í¬ì†Œ ì–´í…ì…˜ (O(nÂ²) â†’ O(n) ìµœì í™”)")
        print("   - íŒ¨í„´ ê¸°ë°˜ ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„±")
        print("   - ì‹ ë¢°ë„ ê¸°ë°˜ ì¢…ë£Œ íŒë‹¨")
        print("   - ì¡°ê¸° ì¢…ë£Œ ë©”ì»¤ë‹ˆì¦˜")
        print("   - í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ")
        print("   - ëª¨ë“ˆ ê°„ í†µí•© ë™ì‘")
        return True
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
