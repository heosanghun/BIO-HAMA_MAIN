#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ BioHama ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸

ìƒˆë¡œ êµ¬í˜„ëœ SparseAttentionê³¼ TerminationModuleì˜ í†µí•© ë™ì‘ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
from typing import Dict, Any

# BioHama ëª¨ë“ˆ import
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from biohama.core.sparse_attention import SparseAttentionModule
from biohama.core.termination_module import TerminationModule


def test_module_integration():
    """ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ”— BioHama ê³ ê¸‰ ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ì„¤ì •
    sparse_config = {
        'name': 'TestSparseAttention',
        'd_model': 256,
        'num_heads': 4,
        'seq_len': 64,
        'sparsity_ratio': 0.8,
        'local_window': 16,
        'pattern_dim': 32,
        'num_patterns': 4
    }
    
    termination_config = {
        'name': 'TestTermination',
        'input_dim': 256,
        'confidence_threshold': 0.6,
        'quality_threshold': 0.5,
        'patience': 3,
        'min_delta': 0.01,
        'max_iterations': 10
    }
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    print("ğŸ”„ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")
    sparse_attention = SparseAttentionModule(sparse_config)
    termination = TerminationModule(termination_config)
    print("âœ… ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
    scenarios = [
        {
            'name': 'ê¸°ë³¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬',
            'query': torch.randn(1, 32, 256),
            'features': torch.randn(1, 32, 256),
            'iteration': 0
        },
        {
            'name': 'ê¸´ ì‹œí€€ìŠ¤ ì²˜ë¦¬',
            'query': torch.randn(1, 64, 256),
            'features': torch.randn(1, 64, 256),
            'iteration': 1
        },
        {
            'name': 'ë°°ì¹˜ ì²˜ë¦¬',
            'query': torch.randn(4, 32, 256),
            'features': torch.randn(4, 32, 256),
            'iteration': 2
        }
    ]
    
    print(f"\nğŸ“‹ {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰")
    print("-" * 80)
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\nğŸ”„ ì‹œë‚˜ë¦¬ì˜¤ {i}: {scenario['name']}")
        print(f"   ì…ë ¥ í¬ê¸°: {scenario['query'].shape}")
        
        try:
            # 1. í¬ì†Œ ì–´í…ì…˜ ì²˜ë¦¬
            sparse_inputs = {
                'query': scenario['query'],
                'seq_len': scenario['query'].size(1)
            }
            sparse_outputs = sparse_attention(sparse_inputs)
            
            print(f"   âœ… í¬ì†Œ ì–´í…ì…˜ ì™„ë£Œ")
            print(f"   í¬ì†Œì„±: {sparse_outputs['sparsity_ratio']:.3f}")
            print(f"   ê³„ì‚° ì ˆì•½: {sparse_outputs['computation_savings']:.3f}")
            
            # 2. ì¢…ë£Œ íŒë‹¨
            termination_inputs = {
                'features': scenario['features'],
                'iteration': scenario['iteration'],
                'force_continue': False
            }
            termination_outputs = termination(termination_inputs)
            
            print(f"   âœ… ì¢…ë£Œ íŒë‹¨ ì™„ë£Œ")
            print(f"   ì‹ ë¢°ë„: {termination_outputs['confidence'].mean().item():.3f}")
            print(f"   í’ˆì§ˆ: {termination_outputs['quality'].mean().item():.3f}")
            print(f"   ì¢…ë£Œ ì—¬ë¶€: {termination_outputs['should_terminate']}")
            
            if termination_outputs['should_terminate']:
                print(f"   ğŸ”´ ì¡°ê¸° ì¢…ë£Œë¨!")
            else:
                print(f"   ğŸŸ¢ ê³„ì† ì§„í–‰")
                
        except Exception as e:
            print(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    # í†µí•© í†µê³„
    print(f"\nğŸ“Š í†µí•© í†µê³„")
    print("-" * 80)
    
    sparse_stats = sparse_attention.get_attention_stats()
    termination_stats = termination.get_termination_stats()
    
    print(f"í¬ì†Œ ì–´í…ì…˜:")
    print(f"  ì´ í† í°: {sparse_stats['total_tokens']:,}")
    print(f"  í¬ì†Œ í† í°: {sparse_stats['sparse_tokens']:,}")
    print(f"  ê³„ì‚° ì ˆì•½: {sparse_stats['computation_savings']:.3f}")
    print(f"  íŒ¨í„´ ë§¤ì¹­: {sparse_stats['pattern_matches']:.2f}")
    
    print(f"\nì¢…ë£Œ ëª¨ë“ˆ:")
    print(f"  ì´ ì²´í¬: {termination_stats['total_checks']}")
    print(f"  ì¡°ê¸° ì¢…ë£Œ: {termination_stats['early_terminations']}")
    print(f"  í‰ê·  ë°˜ë³µ: {termination_stats['avg_iterations']:.2f}")
    print(f"  í‰ê·  ì‹ ë¢°ë„: {termination_stats['avg_confidence']:.3f}")
    print(f"  í‰ê·  í’ˆì§ˆ: {termination_stats['avg_quality']:.3f}")
    
    return True


def test_performance_benchmark():
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ì„¤ì •
    sparse_config = {
        'name': 'BenchmarkSparse',
        'd_model': 512,
        'num_heads': 8,
        'seq_len': 128,
        'sparsity_ratio': 0.9,  # ë†’ì€ í¬ì†Œì„±
        'local_window': 32,
        'pattern_dim': 64,
        'num_patterns': 8
    }
    
    termination_config = {
        'name': 'BenchmarkTermination',
        'input_dim': 512,
        'confidence_threshold': 0.5,
        'quality_threshold': 0.4,
        'patience': 2,
        'min_delta': 0.01,
        'max_iterations': 5
    }
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    sparse_attention = SparseAttentionModule(sparse_config)
    termination = TerminationModule(termination_config)
    
    print("ğŸ”„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    # ëŒ€ìš©ëŸ‰ ì…ë ¥
    batch_size = 8
    seq_len = 128
    d_model = 512
    
    query = torch.randn(batch_size, seq_len, d_model)
    features = torch.randn(batch_size, seq_len, d_model)
    
    import time
    
    # í¬ì†Œ ì–´í…ì…˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ§  í¬ì†Œ ì–´í…ì…˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print(f"   ì…ë ¥ í¬ê¸°: {query.shape}")
    
    start_time = time.time()
    for i in range(10):
        sparse_inputs = {'query': query, 'seq_len': seq_len}
        sparse_outputs = sparse_attention(sparse_inputs)
        
        if i == 0:
            first_time = time.time() - start_time
            print(f"   ì²« ë²ˆì§¸ ì²˜ë¦¬ ì‹œê°„: {first_time:.3f}ì´ˆ")
            print(f"   í¬ì†Œì„±: {sparse_outputs['sparsity_ratio']:.3f}")
    
    total_time = time.time() - start_time
    avg_time = total_time / 10
    
    print(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.3f}ì´ˆ")
    print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.3f}ì´ˆ")
    print(f"   ì²˜ë¦¬ ì†ë„: {10/total_time:.1f} ìš”ì²­/ì´ˆ")
    
    # ì¢…ë£Œ ëª¨ë“ˆ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ›‘ ì¢…ë£Œ ëª¨ë“ˆ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print(f"   ì…ë ¥ í¬ê¸°: {features.shape}")
    
    start_time = time.time()
    for i in range(10):
        termination_inputs = {
            'features': features,
            'iteration': i,
            'force_continue': False
        }
        termination_outputs = termination(termination_inputs)
        
        if i == 0:
            first_time = time.time() - start_time
            print(f"   ì²« ë²ˆì§¸ ì²˜ë¦¬ ì‹œê°„: {first_time:.3f}ì´ˆ")
            print(f"   ì‹ ë¢°ë„: {termination_outputs['confidence'].mean().item():.3f}")
    
    total_time = time.time() - start_time
    avg_time = total_time / 10
    
    print(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.3f}ì´ˆ")
    print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.3f}ì´ˆ")
    print(f"   ì²˜ë¦¬ ì†ë„: {10/total_time:.1f} ìš”ì²­/ì´ˆ")
    
    return True


def test_advanced_features():
    """ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("ğŸ¯ ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ì„¤ì •
    sparse_config = {
        'name': 'AdvancedSparse',
        'd_model': 256,
        'num_heads': 4,
        'seq_len': 64,
        'sparsity_ratio': 0.7,
        'local_window': 16,
        'pattern_dim': 32,
        'num_patterns': 4
    }
    
    termination_config = {
        'name': 'AdvancedTermination',
        'input_dim': 256,
        'confidence_threshold': 0.6,
        'quality_threshold': 0.5,
        'patience': 3,
        'min_delta': 0.01,
        'max_iterations': 10
    }
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    sparse_attention = SparseAttentionModule(sparse_config)
    termination = TerminationModule(termination_config)
    
    print("ğŸ”„ ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    # 1. ë™ì  í¬ì†Œì„± ì¡°ì •
    print(f"\n1ï¸âƒ£ ë™ì  í¬ì†Œì„± ì¡°ì • í…ŒìŠ¤íŠ¸")
    
    query = torch.randn(1, 32, 256)
    features = torch.randn(1, 32, 256)
    
    for sparsity in [0.5, 0.7, 0.9]:
        sparse_attention.set_sparsity_ratio(sparsity)
        
        sparse_inputs = {'query': query, 'seq_len': 32}
        sparse_outputs = sparse_attention(sparse_inputs)
        
        print(f"   í¬ì†Œì„± {sparsity}: ì‹¤ì œ {sparse_outputs['sparsity_ratio']:.3f}")
    
    # 2. ë™ì  ì„ê³„ê°’ ì¡°ì •
    print(f"\n2ï¸âƒ£ ë™ì  ì„ê³„ê°’ ì¡°ì • í…ŒìŠ¤íŠ¸")
    
    for confidence_threshold in [0.4, 0.6, 0.8]:
        termination.set_thresholds(confidence_threshold=confidence_threshold)
        
        termination_inputs = {
            'features': features,
            'iteration': 0,
            'force_continue': False
        }
        termination_outputs = termination(termination_inputs)
        
        print(f"   ì‹ ë¢°ë„ ì„ê³„ê°’ {confidence_threshold}: ì‹¤ì œ ì‹ ë¢°ë„ {termination_outputs['confidence'].mean().item():.3f}")
    
    # 3. íŒ¨í„´ í•™ìŠµ í…ŒìŠ¤íŠ¸
    print(f"\n3ï¸âƒ£ íŒ¨í„´ í•™ìŠµ í…ŒìŠ¤íŠ¸")
    
    # ìƒˆë¡œìš´ íŒ¨í„´ ìƒì„±
    new_patterns = torch.randn(4, 32) * 0.1
    sparse_attention.update_patterns(new_patterns)
    print(f"   íŒ¨í„´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    
    # 4. ìƒíƒœ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    print(f"\n4ï¸âƒ£ ìƒíƒœ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
    
    termination.reset_early_stopping()
    sparse_attention.reset_stats()
    termination.reset_stats()
    
    print(f"   ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # 5. ë©”íƒ€ë°ì´í„° ë° ë³µì¡ë„ ì •ë³´
    print(f"\n5ï¸âƒ£ ë©”íƒ€ë°ì´í„° ë° ë³µì¡ë„ ì •ë³´")
    
    sparse_metadata = sparse_attention.get_metadata()
    sparse_complexity = sparse_attention.get_complexity()
    
    termination_metadata = termination.get_metadata()
    termination_complexity = termination.get_complexity()
    
    print(f"   í¬ì†Œ ì–´í…ì…˜:")
    print(f"     ì´ë¦„: {sparse_metadata['name']}")
    print(f"     íƒ€ì…: {sparse_metadata['module_type']}")
    print(f"     íŒŒë¼ë¯¸í„°: {sparse_complexity['total_parameters']:,}")
    
    print(f"   ì¢…ë£Œ ëª¨ë“ˆ:")
    print(f"     ì´ë¦„: {termination_metadata['name']}")
    print(f"     íƒ€ì…: {termination_metadata['module_type']}")
    print(f"     íŒŒë¼ë¯¸í„°: {termination_complexity['total_parameters']:,}")
    
    return True


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ BioHama ê³ ê¸‰ ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    test_results = []
    
    try:
        # ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸
        test_results.append(test_module_integration())
        
        # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
        test_results.append(test_performance_benchmark())
        
        # ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        test_results.append(test_advanced_features())
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“‹ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    
    passed_tests = sum(test_results)
    total_tests = len(test_results)
    
    print(f"âœ… í†µê³¼í•œ í…ŒìŠ¤íŠ¸: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("ğŸ‰ ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        print("\nâœ¨ êµ¬í˜„ëœ ê³ ê¸‰ ê¸°ëŠ¥:")
        print("   - âœ… ë™ì  í¬ì†Œ ì–´í…ì…˜ (O(nÂ²) â†’ O(n) ìµœì í™”)")
        print("   - âœ… íŒ¨í„´ ê¸°ë°˜ ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„±")
        print("   - âœ… ì‹ ë¢°ë„ ê¸°ë°˜ ì¢…ë£Œ íŒë‹¨")
        print("   - âœ… ì¡°ê¸° ì¢…ë£Œ ë©”ì»¤ë‹ˆì¦˜")
        print("   - âœ… í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ")
        print("   - âœ… ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì •")
        print("   - âœ… íŒ¨í„´ í•™ìŠµ ë° ì—…ë°ì´íŠ¸")
        print("   - âœ… ìƒíƒœ ê´€ë¦¬ ë° ì´ˆê¸°í™”")
        print("   - âœ… ì„±ëŠ¥ ìµœì í™”")
        print("   - âœ… ëª¨ë“ˆ ê°„ í†µí•© ë™ì‘")
        print("\nğŸš€ BioHama ê³ ê¸‰ ëª¨ë“ˆì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return True
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
